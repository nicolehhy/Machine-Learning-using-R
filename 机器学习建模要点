#####
# 1 # 如何建立线性回归模型 ？
#####

1) 收集/观察数据；
2) 探索和准备数据；
3) 基于数据训练模型；
4) 评估模型的性能；
5) 提高模型的性能。

1）建立模型之前，我们首先要清楚我们需要解决什么问题，我需要什么样的数据。例如我们想知道主播在直播过程中，哪些指标直接影响了他们的直播收益。
清楚了这个业务需求后，我就明白了我需要拿到随机的大批量的主播的直播数据和相应的用户行为数据。初步认为主播的直播频次，直播内容以及用户行为反馈是关键因素。
收集到了数据后，我需要熟悉我的数据，尽可能地挖掘出对这一业务需求有价值的信息。

  通常情况下，我们称这一行为为探索性数据分析（exploratory data analysis EDA)。我一般会采用可视化进行分析，我会画出我认为很重要的变量的分布，
  以及画出各个变量和因变量的相关性视图，从而对数据有一个大致的了解，看我是否需要做标准化处理，独热编码，线性变换或者添加新的变量等等。

2）在此之后，我将进行数据处理。比如说对变量进行标准化处理，对缺失值进行处理，基于某些规则选择有效变量，对于大型数据有时候可能还会涉及到主成分分析（PCA）
之类的降维方法在尽量保持原有数据信息的情况下把它压缩成一个小一点的更容易处理的数据，等等。总之预处理的目的就是希望把整个数据变得更加的干净（clean）
从而能够被统计模型更好的学习，建立的模型也会更加的稳定和准确。然后将数据分成training和testing。

3）选择模型的时候，我们往往需要建立多种模型，通过评估的方法选出最适合这个数据的那一个。我们可以通过RMSE或者roc curve等方法来判断各个模型的准确度。从而
找到最好的模型

在选择线性回归模型的时候，我们需要注意以下几点。
1. 我们希望我们的变量和因变量存在线性关系。一种常用的判断线性性的方法是把残差（residual）作为y轴，拟合值（fitted value）作为x轴画一个残差图
（residual plot）。如果残差图的点以大致恒定的方差（constant variance）大致成对称的分布在x轴附近，则使用线性回归有可能是合理的，
不然不应该使用线性回归。对于不满足线性性的数据强行使用线性回归模型会导致一个非常不准确的结果，在使用此模型做外部推断（extrapolate）
或者说样本外预测（out-of-sample prediction）时会得到错误的数值。

   但我们可以使用以下方法将变量变成线性的。
   a. 对响应变量或者预测变量或者对于两者同时使用合适的非线性变换（nonlinear transformation）。比如说，如果某个变量的值全部都是正的，可以考虑log变换（log
transformation），如果变量大于等于0，则可以考虑log+1变换（log+1 transformation）。举一个具体点的例子，在调查价格和需求的关系（price-demand）时，
经常会发现预测变量的百分比变化会导致响应变量发生相应的百分比变化而且两个变化之间竟然是成近似正比的关系，这时对解释变量和预测变量同时使用log变化再对变化
后的变量搞一个线性回归就很合理了。

  b. 可以考虑造一些新的预测变量加入到数据中。使得新加入的变量与已有的预测变量x有某种非线性关系。比方说，加入x^2或者x^3或者甚至于更高阶的。
  但这个办法常常会引入过拟合（overfitting， 后面文章具体讲）的问题。




